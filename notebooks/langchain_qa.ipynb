{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df225cc4-b746-4c50-b52f-8ede49daf1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget -r -A.html -P rtdocs https://langchain.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0a3b218-d8c3-4bfd-8500-0a91e553448f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5966e51-5e65-4764-bb56-ddf0f48d3327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import ReadTheDocsLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "from virtual_assistant.utilities import GoogleSerperAPIWrapper, initialize_pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b92f0941-930b-47d0-8b9f-1cee3cfdf509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "030b6a71-d235-40c9-8d27-768ed52a591a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='.md\\n.pdf\\nTracing\\n Contents \\nTracing Walkthrough\\nChanging Sessions\\nTracing#\\nBy enabling tracing in your LangChain runs, you’ll be able to more effectively visualize, step through, and debug your chains and agents.\\nFirst, you should install tracing and set up your environment properly.\\nYou can use either a locally hosted version of this (uses Docker) or a cloud hosted version (in closed alpha).\\nIf you’re interested in using the hosted platform, please fill out the form here.\\nLocally Hosted Setup\\nCloud Hosted Setup\\nTracing Walkthrough#\\nWhen you first access the UI, you should see a page with your tracing sessions.\\nAn initial one “default” should already be created for you.\\nA session is just a way to group traces together.\\nIf you click on a session, it will take you to a page with no recorded traces that says “No Runs.”\\nYou can create a new session with the new session form.\\nIf we click on the default session, we can see that to start we have no traces stored.\\nIf we now start running chains and agents with tracing enabled, we will see data show up here.\\nTo do so, we can run this notebook as an example.\\nAfter running it, we will see an initial trace show up.\\nFrom here we can explore the trace at a high level by clicking on the arrow to show nested runs.\\nWe can keep on clicking further and further down to explore deeper and deeper.\\nWe can also click on the “Explore” button of the top level run to dive even deeper.\\nHere, we can see the inputs and outputs in full, as well as all the nested traces.\\nWe can keep on exploring each of these nested traces in more detail.\\nFor example, here is the lowest level trace with the exact inputs/outputs to the LLM.\\nChanging Sessions#\\nTo initially record traces to a session other than \"default\", you can set the LANGCHAIN_SESSION environment variable to the name of the session you want to record to:\\nimport os\\nos.environ[\"LANGCHAIN_HANDLER\"] = \"langchain\"\\nos.environ[\"LANGCHAIN_SESSION\"] = \"my_session\" # Make sure this session actually exists. You can create a new session in the UI.\\nTo switch sessions mid-script or mid-notebook, do NOT set the LANGCHAIN_SESSION environment variable. Instead: langchain.set_tracing_callback_manager(session_name=\"my_session\")\\nprevious\\nDeployments\\n Contents\\n  \\nTracing Walkthrough\\nChanging Sessions\\nBy Harrison Chase\\n    \\n      © Copyright 2023, Harrison Chase.\\n      \\n  Last updated on Apr 14, 2023.\\n  ', metadata={'source': 'rtdocs/python.langchain.com/en/latest/tracing.html'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = ReadTheDocsLoader(\"rtdocs\")\n",
    "raw_documents = loader.load()\n",
    "raw_documents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "930d7a7d-cff2-462d-b6ef-f9bebcf9d2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Pinecone.from_documents(documents, embeddings, index_name=\"personal-knowledgebase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e22d8ff-830e-489c-b619-908f0eeb7b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorstore = Pinecone.from_existing_index(index_name='personal-knowledgebase', embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35ffc4f9-76a6-44ec-97b6-07479a74dae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3d26842-174a-4af3-96a6-678482d47138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "276da9bf-0544-402b-9d5e-536df65c5531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), vectorstore.as_retriever(), return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1de7e39-ec06-4b63-8368-e3921f183927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a6c1a6e-62fe-4fe3-88db-58cb7c785edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What's langchain latest version code\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ffa043-ebf5-4ff7-af7a-4b7e9972b958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
